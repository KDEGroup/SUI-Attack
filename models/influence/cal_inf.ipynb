{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- LOAD DATA in train recommender -----\n",
      "load data from ./data/automotive/preprocess/train.data ...\n",
      "----- LOAD DATA in train recommender -----\n",
      "load data from ./data/automotive/preprocess/test.data ...\n",
      "----- DATA INFO in train recommender -----\n",
      "Number of users : 2928 , Number of items : 1835. \n",
      "Train size : 18425 , Test size : 2048. \n",
      "Saving checkpoint to ./saved/recommender/WMF_sgd.pt\n",
      "Loaded checkpoint from ./saved/recommender/WMF_sgd.pt\n",
      "[Evaluation recommender] topk=[1, 10, 20, 50, 100]\n",
      "precision=[0.04, 0.02, 0.01, 0.01, 0.01], recall=[0.03, 0.14, 0.19, 0.28, 0.36], ndcg=[0.04, 0.04, 0.04, 0.04, 0.04]\n",
      "[Evaluation recommender after attack][0.1 s] topk=[1, 10, 20, 50, 100]\n",
      "HitUserNum=[42], TargetAvgRank=[55.5], TargetHR=[0.0, 0.002, 0.004, 0.012, 0.029], TargetNDCG=[0.0, 0.001, 0.001, 0.003, 0.006]\n",
      "ctr [===================================...................................] 1 / 2\n",
      "ctr [======================================================================] 2 / 2\n",
      "ar: [======================================================================] 1 / 1\n",
      "Cif: [===============================================================] 2927 / 2928928\n",
      "Cif: [===============================================================] 2928 / 2928\n"
     ]
    }
   ],
   "source": [
    "from models.influence import calc_influence_RS_single\n",
    "from models import RecLoader\n",
    "import utils, torch, os\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from torch.utils import data\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from timm.scheduler.cosine_lr import CosineLRScheduler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def normalize(mx):\n",
    "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
    "    rowsum = np.array(mx.sum(1))\n",
    "    r_inv = np.power(rowsum, -0.5).flatten()\n",
    "    r_inv[np.isinf(r_inv)] = 0.\n",
    "    r_mat_inv = sp.diags(r_inv)\n",
    "    mx = r_mat_inv.dot(mx)\n",
    "    mx = mx.dot(r_mat_inv)\n",
    "    return mx\n",
    "\n",
    "# 受害者模型、数据集\n",
    "vicm, dataset = 'CML', 'lastfm'\n",
    "\n",
    "rec = RecLoader()\n",
    "trainarr = rec.train_matrix.toarray()\n",
    "user_feat, _ = utils.init_emb_by_feature(trainarr, name=dataset)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "user_feat = torch.tensor(scaler.fit_transform(user_feat), dtype=torch.float)\n",
    "feat_dim = user_feat.shape[1]\n",
    "train_loader, test_loader = rec.train_loader, rec.train_loader\n",
    "model, test_id_num, gpu = rec.net, range(user_feat.shape[0]), -1\n",
    "rd, r = 2, 1\n",
    "influence, harmful, helpful, _ = calc_influence_RS_single(model, train_loader, test_loader, test_id_num, gpu, rd, r)\n",
    "inf_dict = {}\n",
    "for h, i in zip(harmful, influence):\n",
    "    inf_dict[h] = i.item()\n",
    "influence = torch.tensor([inf_dict[i] for i in range(len(influence))], dtype=torch.float).reshape(-1, 1)\n",
    "\n",
    "tensorset = data.TensorDataset(user_feat, influence)\n",
    "iter_data = data.DataLoader(tensorset, batch_size=32, shuffle=True)\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        m.weight.data.normal_(0, 0.01)\n",
    "        m.bias.data.normal_(0)\n",
    "\n",
    "net = torch.nn.Sequential(\n",
    "    nn.Linear(feat_dim, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 1)\n",
    ")\n",
    "\n",
    "if not os.path.exists(f'./saved/influence/{dataset}_{vicm}.pt'):\n",
    "    net.apply(init_weights)\n",
    "    loss, epochs = nn.MSELoss(), 200\n",
    "    optimizer = torch.optim.Adam(lr=1e-5, params=net.parameters())\n",
    "\n",
    "    num_steps = epochs * len(iter_data)\n",
    "    lr_scheduler = CosineLRScheduler(\n",
    "                optimizer,\n",
    "                t_initial=num_steps,\n",
    "                lr_min=5e-6,\n",
    "                cycle_limit=1,\n",
    "                t_in_epochs=False,\n",
    "    )\n",
    "    for epoch in range(epochs):\n",
    "        losses = []\n",
    "        for idx, (x, y) in enumerate(iter_data):\n",
    "            l = loss(net(x), y)\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step_update(epoch * num_steps + idx)\n",
    "            losses.append(l.item())\n",
    "    torch.save(net.state_dict(), f'./saved/influence/{dataset}_{vicm}.pt')\n",
    "else:\n",
    "    net.load_state_dict(torch.load(f'./saved/influence/{dataset}_{vicm}.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9791], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(user_feat[98])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b7be09b453a5166891a9a5ff4a92c376f2892b7e4430cb3ba5337d84258b4ab4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.15 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
